{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.16.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model + Draw Keypoints + Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='movenet_lighting_tflite_float16.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    # for kp in shaped:\n",
    "    #     ky, kx, kp_conf = kp\n",
    "    #     if kp_conf > confidence_threshold:\n",
    "    #         cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        # if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "        #     cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어깨 중간과 엉덩이 중간에 세로선 그리기 추가\n",
    "def draw_midline(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))\n",
    "\n",
    "    shoulder_mid = (shaped[5][:2] + shaped[6][:2]) / 2\n",
    "    hip_mid = (shaped[11][:2] + shaped[12][:2]) / 2\n",
    "\n",
    "    # if (shaped[5][2] > confidence_threshold and shaped[6][2] > confidence_threshold and\n",
    "    #         shaped[11][2] > confidence_threshold and shaped[12][2] > confidence_threshold):\n",
    "    #     cv2.line(frame, (int(shoulder_mid[1]), int(shoulder_mid[0])), (int(hip_mid[1]), int(hip_mid[0])), (255, 0, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_face_axis(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))\n",
    "\n",
    "    # 얼굴의 중심축을 찾기 위한 키포인트 정의\n",
    "    right_eye = shaped[2][:2]\n",
    "    left_eye = shaped[1][:2]\n",
    "    right_ear = shaped[4][:2]\n",
    "    left_ear = shaped[3][:2]\n",
    "\n",
    "    # 눈의 중간 지점(코로 가정)과 귀의 중간 지점 계산\n",
    "    nose = (right_eye + left_eye) / 2\n",
    "    ears_mid = (right_ear + left_ear) / 2\n",
    "\n",
    "    # 눈의 중간 지점과 귀의 중간 지점을 연결하는 선 그리기\n",
    "    # if (shaped[2][2] > confidence_threshold and shaped[1][2] > confidence_threshold and\n",
    "    #     shaped[4][2] > confidence_threshold and shaped[3][2] > confidence_threshold):\n",
    "    #     cv2.line(frame, (int(nose[1]), int(nose[0])), (int(ears_mid[1]), int(ears_mid[0])), (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_face_vertical_line(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))\n",
    "\n",
    "    # 머리 상단과 목 위치를 사용하여 대략적인 이마와 턱의 위치 추정\n",
    "    head_top = shaped[0][:2]  # 머리 상단(이마로 가정)\n",
    "    neck = shaped[1][:2]  # 목(턱 근처로 가정)\n",
    "\n",
    "    # if (shaped[0][2] > confidence_threshold and shaped[1][2] > confidence_threshold):\n",
    "    #     # 이마에서 턱까지의 선 그리기\n",
    "    #     cv2.line(frame, (int(head_top[1]), int(head_top[0])), (int(neck[1]), int(neck[0])), (0, 0, 255), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_address_pose(keypoints_with_scores, confidence_threshold=0.4):\n",
    "    keypoints = np.squeeze(keypoints_with_scores)\n",
    "    \n",
    "    # 키포인트 신뢰도 체크\n",
    "    if (keypoints[5][2] < confidence_threshold or keypoints[6][2] < confidence_threshold or\n",
    "        keypoints[11][2] < confidence_threshold or keypoints[12][2] < confidence_threshold):\n",
    "        return False  # 신뢰도가 임계값 미만인 키포인트가 있으면 어드레스 자세로 판단하지 않음\n",
    "    \n",
    "    # 어깨와 골반의 중간점 계산\n",
    "    shoulder_midpoint = (keypoints[5][:2] + keypoints[6][:2]) / 2\n",
    "    hip_midpoint = (keypoints[11][:2] + keypoints[12][:2]) / 2\n",
    "\n",
    "    # print(\"어드레스\")\n",
    "    \n",
    "    # 어깨와 골반의 높이 차이 계산\n",
    "    vertical_diff = abs(shoulder_midpoint[1] - hip_midpoint[1])\n",
    "    \n",
    "    # 높이 차이 임계값을 조정하여 수평성 체크\n",
    "    vertical_diff_threshold = 5  # 높이 차이 임계값을 5로 조정 (상황에 따라 조정 가능)\n",
    "    if vertical_diff < vertical_diff_threshold:\n",
    "        return True  # 어깨와 골반의 높이 차이가 임계값 이하이면 어드레스 자세로 판별\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(p1, p2):\n",
    "    \"\"\"두 점 p1, p2 간의 각도를 계산합니다.\"\"\"\n",
    "    angle = np.arctan2(p2[1] - p1[1], p2[0] - p1[0]) * 180.0 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_body_straight(keypoints_with_scores, confidence_threshold=0.4):\n",
    "    keypoints = np.squeeze(keypoints_with_scores)\n",
    "    head_point = keypoints[0, :2]\n",
    "    neck_point = keypoints[1, :2]\n",
    "    hip_center = (keypoints[11, :2] + keypoints[12, :2]) / 2\n",
    "    \n",
    "    # print(\"바디바디\")\n",
    "    \n",
    "    # 머리-목 각도와 목-골반 각도를 계산\n",
    "    head_neck_angle = calculate_angle(head_point, neck_point)\n",
    "    neck_hip_angle = calculate_angle(neck_point, hip_center)\n",
    "\n",
    "    # print(\"바디바디222\")\n",
    "    \n",
    "    # 각도 차이를 계산\n",
    "    angle_diff = abs(head_neck_angle - neck_hip_angle)\n",
    "\n",
    "    print(f\"계산된 각도 차이: {angle_diff}\")\n",
    "    \n",
    "    # 조건을 만족하면 True 반환\n",
    "    if angle_diff < 165 and angle_diff > 145:  # 이 값은 조정 가능합니다.\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 316,\n",
       "  'shape': array([ 1,  1, 17,  3]),\n",
       "  'shape_signature': array([ 1,  1, 17,  3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaped = np.squeeze(np.multiply(interpreter.get_tensor(interpreter.get_output_details()[0]['index']), [480,640,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "for edge, color in EDGES.items():\n",
    "    p1, p2 = edge\n",
    "    y1, x1, c1 = shaped[p1]\n",
    "    y2, x2, c2 = shaped[p2]\n",
    "    print((int(x2), int(y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n",
      "0 0 0.0\n"
     ]
    }
   ],
   "source": [
    "for kp in shaped:\n",
    "    ky, kx, kp_conf = kp\n",
    "    print(int(ky), int(kx), kp_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n",
      "어드레스 자세 아님.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    \n",
    "    # input_image = tf.cast(img, dtype=tf.float32)\n",
    "    # 모델이 요구하는 입력 타입에 맞게 타입 변환\n",
    "    input_image = tf.cast(img, dtype=tf.uint8)  # dtype을 tf.float32에서 tf.uint8로 변경\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    right_eye = keypoints_with_scores[0][0][2]\n",
    "    left_elbow = keypoints_with_scores[0][0][7]\n",
    "    \n",
    "    # Rendering \n",
    "    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    # 기존 렌더링 코드 아래에 세로선 그리기 함수 호출 추가\n",
    "    draw_midline(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "    # 얼굴 중심축 그리기 함수 호출\n",
    "    draw_face_axis(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "\n",
    "    #   # 어드레스 자세 판별\n",
    "    # if is_address_pose(keypoints_with_scores, 0.4):\n",
    "    #     print(\"어드레스 자세 감지됨!\")\n",
    "    #     time.sleep(2)\n",
    "    #     # 어드레스 자세가 감지되면 콘솔에 메시지 출력\n",
    "    #     # 어드레스 자세 감지 시 수행할 추가 작업을 여기에 구현할 수 있습니다.\n",
    "    # else:\n",
    "    #     print(\"어드레스 자세 아님.\")  # 어드레스 자세가 아니면 콘솔에 메시지 출력\n",
    "    #     time.sleep(2)\n",
    "\n",
    "    if is_address_pose(keypoints_with_scores, 0.4) and is_body_straight(keypoints_with_scores, 0.4):\n",
    "        print(\"어드레스 자세 감지됨!\")  # 어드레스 자세와 몸통이 똑바로 서 있는 상태 감지\n",
    "        # time.sleep(1)\n",
    "    else:\n",
    "        print(\"어드레스 자세 아님.\")\n",
    "        # time.sleep(1)\n",
    "    \n",
    "    cv2.imshow('MoveNet Lightning', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머리-목 축과 목-골반 축의 각 계산하여 어드레스 자세 감지\n",
    "\n",
    "\n",
    "\n",
    "아이언 어드레스 -> 어드레스 자세 아님\n",
    "\n",
    "드라이버 어드레스  -> 어드레스 자세 감지됨!\n",
    "\n",
    "(angle_diff 범위 수정하여 특정 자세 감지하도록 설정)\n",
    "\n",
    "print()문이 어깨 + 골반 관절 감지 안했을때 안나오는 이유??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
